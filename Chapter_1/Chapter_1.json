{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781155591_-1552707128","id":"20190420-102555_893668907","dateCreated":"2019-04-20T10:25:55-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:231","text":"import org.apache.spark.sql.SparkSession\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\n\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level","dateUpdated":"2019-04-20T10:26:19-0700","dateFinished":"2019-04-20T10:27:34-0700","dateStarted":"2019-04-20T10:26:19-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SparkSession\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781179303_-2062956037","id":"20190420-102619_1762300037","dateCreated":"2019-04-20T10:26:19-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:384","text":"import spark.implicits._\n\nvar CryotherapyDF = spark.read.option(\"header\", \"true\")\n      .option(\"inferSchema\", \"true\")\n      .csv(\"/home/asif/data/Cryotherapy.csv\")\n","dateUpdated":"2019-04-20T10:30:01-0700","dateFinished":"2019-04-20T10:30:20-0700","dateStarted":"2019-04-20T10:30:01-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nCryotherapyDF: org.apache.spark.sql.DataFrame = [sex: int, age: int ... 5 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.231.152:4040/jobs/job?id=0","http://192.168.231.152:4040/jobs/job?id=1"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781305162_-427459602","id":"20190420-102825_1625943186","dateCreated":"2019-04-20T10:28:25-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:614","text":"CryotherapyDF.printSchema()\nCryotherapyDF.show(10)","dateUpdated":"2019-04-20T10:30:47-0700","dateFinished":"2019-04-20T10:30:33-0700","dateStarted":"2019-04-20T10:30:31-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- sex: integer (nullable = true)\n |-- age: integer (nullable = true)\n |-- Time: double (nullable = true)\n |-- Number_of_Warts: integer (nullable = true)\n |-- Type: integer (nullable = true)\n |-- Area: integer (nullable = true)\n |-- Result_of_Treatment: integer (nullable = true)\n\n+---+---+-----+---------------+----+----+-------------------+\n|sex|age| Time|Number_of_Warts|Type|Area|Result_of_Treatment|\n+---+---+-----+---------------+----+----+-------------------+\n|  1| 35| 12.0|              5|   1| 100|                  0|\n|  1| 29|  7.0|              5|   1|  96|                  1|\n|  1| 50|  8.0|              1|   3| 132|                  0|\n|  1| 32|11.75|              7|   3| 750|                  0|\n|  1| 67| 9.25|              1|   1|  42|                  0|\n|  1| 41|  8.0|              2|   2|  20|                  1|\n|  1| 36| 11.0|              2|   1|   8|                  0|\n|  1| 59|  3.5|              3|   3|  20|                  0|\n|  1| 20|  4.5|             12|   1|   6|                  1|\n|  2| 34|11.25|              3|   3| 150|                  0|\n+---+---+-----+---------------+----+----+-------------------+\nonly showing top 10 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.231.152:4040/jobs/job?id=2"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781431222_-395395161","id":"20190420-103031_408108196","dateCreated":"2019-04-20T10:30:31-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:763","text":"//Since Spark ML algorithm expect a 'label' column, which is in our case 'Survived\". Let's rename it to 'label'\nCryotherapyDF = CryotherapyDF.withColumnRenamed(\"Result_of_Treatment\", \"label\")\nCryotherapyDF.printSchema()","dateUpdated":"2019-04-20T10:31:07-0700","dateFinished":"2019-04-20T10:31:09-0700","dateStarted":"2019-04-20T10:31:07-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- sex: integer (nullable = true)\n |-- age: integer (nullable = true)\n |-- Time: double (nullable = true)\n |-- Number_of_Warts: integer (nullable = true)\n |-- Type: integer (nullable = true)\n |-- Area: integer (nullable = true)\n |-- label: integer (nullable = true)\n\nCryotherapyDF: org.apache.spark.sql.DataFrame = [sex: int, age: int ... 5 more fields]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781467761_561293090","id":"20190420-103107_1049387859","dateCreated":"2019-04-20T10:31:07-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:879","text":"//Select columns for preparing training data using VectorAssembler()\nval selectedCols = Array(\"sex\", \"age\", \"Time\", \"Number_of_Warts\", \"Type\", \"Area\")\n\nval vectorAssembler = new VectorAssembler()\n      .setInputCols(selectedCols)\n      .setOutputCol(\"features\")\n\n// We convert prepare a training data containing \"label\" and \"features\", where the features contains existing numeric features and one hot encoded ones: \nval numericDF = vectorAssembler.transform(CryotherapyDF)\n      .select(\"label\", \"features\")\nnumericDF.show(10)","dateUpdated":"2019-04-20T10:31:39-0700","dateFinished":"2019-04-20T10:31:46-0700","dateStarted":"2019-04-20T10:31:39-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|[1.0,35.0,12.0,5....|\n|    1|[1.0,29.0,7.0,5.0...|\n|    0|[1.0,50.0,8.0,1.0...|\n|    0|[1.0,32.0,11.75,7...|\n|    0|[1.0,67.0,9.25,1....|\n|    1|[1.0,41.0,8.0,2.0...|\n|    0|[1.0,36.0,11.0,2....|\n|    0|[1.0,59.0,3.5,3.0...|\n|    1|[1.0,20.0,4.5,12....|\n|    0|[2.0,34.0,11.25,3...|\n+-----+--------------------+\nonly showing top 10 rows\n\nselectedCols: Array[String] = Array(sex, age, Time, Number_of_Warts, Type, Area)\nvectorAssembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_86559bbddbc9\nnumericDF: org.apache.spark.sql.DataFrame = [label: int, features: vector]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.231.152:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781499696_580143904","id":"20190420-103139_1457553566","dateCreated":"2019-04-20T10:31:39-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:979","text":"// Spliting the training data into train and test sets. We use 60% for the training and the rest 40% for testing \nval splits = numericDF.randomSplit(Array(0.8, 0.2))\nval trainDF = splits(0)\nval testDF = splits(1)","dateUpdated":"2019-04-20T10:32:16-0700","dateFinished":"2019-04-20T10:32:19-0700","dateStarted":"2019-04-20T10:32:16-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"splits: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = Array([label: int, features: vector], [label: int, features: vector])\ntrainDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, features: vector]\ntestDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, features: vector]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781536165_-1010278129","id":"20190420-103216_404078056","dateCreated":"2019-04-20T10:32:16-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1098","text":" // Train a DecisionTree model.\nval dt = new DecisionTreeClassifier()\n      .setImpurity(\"gini\")\n      .setMaxBins(10)\n      .setMaxDepth(30)\n      .setLabelCol(\"label\")\n      .setFeaturesCol(\"features\")\n\n// Train model. This also runs the indexers.\nval dtModel = dt.fit(trainDF)","dateUpdated":"2019-04-20T10:32:40-0700","dateFinished":"2019-04-20T10:32:50-0700","dateStarted":"2019-04-20T10:32:40-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dt: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_4307d268747c\ndtModel: org.apache.spark.ml.classification.DecisionTreeClassificationModel = DecisionTreeClassificationModel (uid=dtc_4307d268747c) of depth 6 with 17 nodes\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.231.152:4040/jobs/job?id=4","http://192.168.231.152:4040/jobs/job?id=5","http://192.168.231.152:4040/jobs/job?id=6","http://192.168.231.152:4040/jobs/job?id=7","http://192.168.231.152:4040/jobs/job?id=8","http://192.168.231.152:4040/jobs/job?id=9","http://192.168.231.152:4040/jobs/job?id=10","http://192.168.231.152:4040/jobs/job?id=11","http://192.168.231.152:4040/jobs/job?id=12","http://192.168.231.152:4040/jobs/job?id=13"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781560565_1601131551","id":"20190420-103240_930921557","dateCreated":"2019-04-20T10:32:40-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1198","text":"// Since it's a binary clasisfication problem, we need BinaryClassificationEvaluator() estimator to evaluatemodel's performance on the test set\nval evaluator = new BinaryClassificationEvaluator()\n      .setLabelCol(\"label\")\n\n// Making predictions on test set\nval predictionDF = dtModel.transform(testDF)\n\n//Computing classification accuracy\nval accuracy = evaluator.evaluate(predictionDF)\nprintln(\"Accuracy =  \" + accuracy)","dateUpdated":"2019-04-20T10:33:14-0700","dateFinished":"2019-04-20T10:33:20-0700","dateStarted":"2019-04-20T10:33:15-0700","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Accuracy =  0.9316239316239314\nevaluator: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_3915961626d5\npredictionDF: org.apache.spark.sql.DataFrame = [label: int, features: vector ... 3 more fields]\naccuracy: Double = 0.9316239316239314\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.231.152:4040/jobs/job?id=14","http://192.168.231.152:4040/jobs/job?id=15","http://192.168.231.152:4040/jobs/job?id=16"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1555781594757_-1841976586","id":"20190420-103314_1350343227","dateCreated":"2019-04-20T10:33:14-0700","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1342"}],"name":"Chapter 1","id":"2EB5FNRYA","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}